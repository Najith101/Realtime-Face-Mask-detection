{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mask_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRADtWUdzzH4"
      },
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs7NPCbgz7-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a36697-4f69-4d14-fe70-914fa3eca922"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAza8RwBzzIj",
        "scrolled": true
      },
      "source": [
        "def data_preprocessing():\n",
        "  directory=\"/content/drive/MyDrive/classification/dataset/\"\n",
        "  categories=[\"with_mask\",\"without_mask\"]\n",
        "  #lists where the values needs to be stored\n",
        "  data=[]\n",
        "  label=[]\n",
        "  for category in categories:\n",
        "      path=os.path.join(directory,category)\n",
        "      for img in os.listdir(path):\n",
        "          img_path=os.path.join(path,img)\n",
        "          image=load_img(img_path,target_size=(224,224))\n",
        "          image=img_to_array(image)\n",
        "          image=preprocess_input(image)\n",
        "\n",
        "          #appending the values    \n",
        "          data.append(image)\n",
        "          label.append(category)\n",
        "\n",
        "  #encoding the label\n",
        "  label=LabelEncoder().fit_transform(label)\n",
        "  label=to_categorical(label)\n",
        "\n",
        "  #converting the data and label into a numpy array\n",
        "  data = np.array(data, dtype=\"float32\")\n",
        "  label = np.array(label) \n",
        "\n",
        "  #returning the lists\n",
        "  return data,label"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8_DGb8h8CLo"
      },
      "source": [
        "def image_augumentation():\n",
        "  #constructing image data generator for image augumentation\n",
        "  datagen=ImageDataGenerator(\n",
        "      rotation_range=90,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True\n",
        "      )\n",
        "  return datagen"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXG4g80zzIv"
      },
      "source": [
        "def create_model():\n",
        "  #constructing the base model using resnet50 with the head left off\n",
        "  base_Model=ResNet50(weights=\"imagenet\",include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
        "  #constructing the head of the model\n",
        "  model=Flatten()(base_Model.output)\n",
        "  model=Dense(100,activation=\"relu\",kernel_initializer=\"he_uniform\")(model)\n",
        "  model=Dense(2,activation=\"softmax\")(model)\n",
        "  model=Model(inputs=base_Model.input, outputs=model)\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPPbCeF4zzIr"
      },
      "source": [
        "def run_system():\n",
        "  #data\n",
        "  data,label=data_preprocessing()\n",
        "  #split the dataset\n",
        "  X_train,X_test,y_train,y_test=train_test_split(data,label,test_size=0.20, random_state=42)\n",
        "  #image augumentation\n",
        "  datagen=image_augumentation()\n",
        "  #get the created model\n",
        "  model=create_model()\n",
        "  #fit the model\n",
        "  batch_size=32\n",
        "  model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), \n",
        "                      epochs=9, # one forward/backward pass of training data\n",
        "                      steps_per_epoch=X_train.shape[0]//batch_size, # number of images comprising of one epoch\n",
        "                      validation_data=(X_test, y_test), # data for validation\n",
        "                      validation_steps=X_test.shape[0]//batch_size)\n",
        "  #evaluating performance\n",
        "  result=model.evaluate(X_test,y_test)\n",
        "  print(\"\\n val loss:{}, val_accuracy:{}%\".format(round(result[0],3),round(result[1]*100,3)))\n",
        "  #saving the model\n",
        "  model.save(\"face_model.h5\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kUEtJOnzzI_",
        "outputId": "90127efa-aca0-4ef8-e2ce-b02fbad4b86f"
      },
      "source": [
        "#runs the entire code\n",
        "run_system()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "95/95 [==============================] - 117s 850ms/step - loss: 1.3240 - accuracy: 0.8138 - val_loss: 6.2753 - val_accuracy: 0.6806\n",
            "Epoch 2/9\n",
            "95/95 [==============================] - 75s 791ms/step - loss: 0.2627 - accuracy: 0.9084 - val_loss: 0.6289 - val_accuracy: 0.8879\n",
            "Epoch 3/9\n",
            "95/95 [==============================] - 75s 791ms/step - loss: 0.1680 - accuracy: 0.9476 - val_loss: 0.1915 - val_accuracy: 0.9400\n",
            "Epoch 4/9\n",
            "95/95 [==============================] - 75s 790ms/step - loss: 0.2016 - accuracy: 0.9331 - val_loss: 0.1703 - val_accuracy: 0.9635\n",
            "Epoch 5/9\n",
            "95/95 [==============================] - 76s 794ms/step - loss: 0.1834 - accuracy: 0.9426 - val_loss: 47.0258 - val_accuracy: 0.5398\n",
            "Epoch 6/9\n",
            "95/95 [==============================] - 75s 793ms/step - loss: 0.2210 - accuracy: 0.9314 - val_loss: 0.1054 - val_accuracy: 0.9648\n",
            "Epoch 7/9\n",
            "95/95 [==============================] - 76s 793ms/step - loss: 0.1695 - accuracy: 0.9446 - val_loss: 0.1300 - val_accuracy: 0.9622\n",
            "Epoch 8/9\n",
            "95/95 [==============================] - 75s 791ms/step - loss: 0.1890 - accuracy: 0.9400 - val_loss: 0.2920 - val_accuracy: 0.9192\n",
            "Epoch 9/9\n",
            "95/95 [==============================] - 76s 795ms/step - loss: 0.1371 - accuracy: 0.9578 - val_loss: 0.1838 - val_accuracy: 0.9557\n",
            "24/24 [==============================] - 7s 274ms/step - loss: 0.1838 - accuracy: 0.9557\n",
            "[0.18377920985221863, 0.9556714296340942]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCzLvGDHYn7h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}